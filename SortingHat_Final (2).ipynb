{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zGFwO9jI60ik"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SortingHat_Chatbot\n",
        "AIDM7040\n",
        "\n"
      ],
      "metadata": {
        "id": "CISCsvUJakbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import lirbary"
      ],
      "metadata": {
        "id": "Yj0IRNQqaxno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the library on your environment\n",
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZGbYA4xThoO",
        "outputId": "335c0c31-17f9-4632-8230-708a3edb7b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=216a610c078bff8ed686b557c890088f14eb2783d1c79105e2d92e3312cad5c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install openai==0.28\n",
        "import openai"
      ],
      "metadata": {
        "id": "CKKMYicJldWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drivePath = '/content/drive'\n",
        "drive.mount(drivePath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoEbd5Rf_DX",
        "outputId": "c3da48c3-f151-47fe-a1db-83977e5cc3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "aGUgmF4uIylY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading advater"
      ],
      "metadata": {
        "id": "zGFwO9jI60ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pillow image manipulation library\n",
        "from PIL import Image\n",
        "\n",
        "#display funtion to present the image inline in Jupyter\n",
        "from IPython.display import display\n",
        "\n",
        "#path to figures directory\n",
        "figuresPath = '/content/drive/MyDrive/Colab Notebooks/figures/'"
      ],
      "metadata": {
        "id": "hVfcKfcqgA1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library\n",
        "import wget\n",
        "import os, pathlib\n",
        "\n",
        "# Setup URL and path variables\n",
        "baseURL = 'https://raw.githubusercontent.com/xyuxiaoyu/AIDM7330/main/'\n",
        "\n",
        "imageName01 = 'User.jpg'\n",
        "imageName02 = 'SortingHat01.jpg'\n",
        "\n",
        "fullURL01 = baseURL + imageName01\n",
        "fullURL02 = baseURL + imageName02\n",
        "\n",
        "# Make sure the figuresPath is defined\n",
        "figuresPath = 'your/desired/path'  # 请将 'your/desired/path' 替换为实际的路径\n",
        "\n",
        "# Ensure directory exists\n",
        "if not os.path.exists(figuresPath):\n",
        "    path = pathlib.Path(figuresPath)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "else:\n",
        "    print('The data path you selected already exists')\n",
        "\n",
        "# Download the files\n",
        "fileName01 = wget.download(fullURL01, out=figuresPath)\n",
        "fileName02 = wget.download(fullURL02, out=figuresPath)\n",
        "\n",
        "# Print the paths of the downloaded images\n",
        "print(f\"The path of the first image is: {fileName01}\")\n",
        "print(f\"The path of the second image is: {fileName02}\")"
      ],
      "metadata": {
        "id": "vw04dofNTetn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcfb742-6733-49b9-ec6f-a4f8ef0caca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data path you selected already exists\n",
            "The path of the first image is: your/desired/path/User (1).jpg\n",
            "The path of the second image is: your/desired/path/SortingHat01 (1).jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading prompt"
      ],
      "metadata": {
        "id": "979zK1Ora4sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== Global Configuration ==================\n",
        "apiKey = '4552df10-1eed-42dd-a5c3-6b54a554afb9'\n",
        "base_url = \"https://ark.cn-beijing.volces.com/api/v3\"\n",
        "\n",
        "# ================== Client Initialization ==================\n",
        "openai.api_key = apiKey\n",
        "openai.api_base = base_url\n",
        "\n",
        "# ================== Prompt Loading ==================\n",
        "def load_prompt():\n",
        "    \"\"\"Load the latest prompts from GitHub.\"\"\"\n",
        "    prompt_url = \"https://raw.githubusercontent.com/xyuxiaoyu/AIDM7330/main/test\"\n",
        "    try:\n",
        "        response = requests.get(prompt_url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            print(\"✅ Prompt loaded successfully\")\n",
        "            return response.text\n",
        "        else:\n",
        "            print(f\"❌ Loading failed (HTTP {response.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ An exception occurred: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Check\n",
        "system_content = load_prompt()\n",
        "print(system_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1bniim6QF2d",
        "outputId": "df18c6cf-dd9d-4f16-fb83-784a40df363f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prompt loaded successfully\n",
            "\n",
            "system_prompt = \"现在开始我们两个人进行对话，你要严格地按照以下这个流程与我进行对话：你说一句话后等我的回复再继续我们的对话，我会和你对话，不要自问自答！牢记你说一句我说一句，不要抢我的台词！在跟我对话的时候不要问选择题，不要给用户选择范围，一定不能问！\n",
            "\n",
            "你是《哈利波特》系列中的分院帽，你只需要扮演分院帽，不需要扮演和你对话的人，也不要扮演其他角色，从始至终都只要扮演分院帽，牢记这一要求！你最重要的任务是通过与用户对话，分析他们的性格和品质，并按照霍格沃茨的四大学院的特点，将他们分配到最适合的学院。接下来会给你更多信息帮助你扮演分院帽，牢记一定要遵守分院帽的身份原则，牢记你在《哈利波特》的魔法世界中，要遵守魔法世界的原则，绝对不能提到有关现实世界的事情，提到伏地魔相关的你要害怕！\n",
            "\n",
            "你的性格：\n",
            "智慧且敏锐：你拥有极高的智慧，能够敏锐地洞察用户的内心想法和性格特点。你善于分析和判断，能够从对话中捕捉到用户的优点和潜力，你会用富有哲理的语言表达自己的观点。\n",
            "有主见但尊重他人意愿：你有自己的判断标准，也会尊重用户的意愿。如果用户对某个学院有强烈的倾向，你会在综合考虑后做出合适的决定。\n",
            "幽默诙谐：你在对话中会带有幽默感，用诙谐的语言与用户交流，缓解紧张的氛围，让分院过程更加轻松愉快。\n",
            "严肃认真：在分院时，你会表现出严肃认真的态度。\n",
            "\n",
            "你说话的语气：\n",
            "权威而自信：在宣布分院结果时，语气要坚定、自信。\n",
            "幽默诙谐：可以用幽默的语言调侃用户，但要注意分寸，避免伤害到对方。\n",
            "严肃认真：在分析用户性格特点时，要表现出你在思考。\n",
            "调侃和讽刺：有时会说一些调侃或者带讽刺的话，并不是恶意的。\n",
            "尊重他人意愿：如果用户不想去你给的学院，你会对他进行劝说，说明他和你选择的学院有什么相似之处，但如果用户坚持要改变，你会尊重他的想法。\n",
            "\n",
            "四大学院的特点：\n",
            "你需要在与用户对话的过程中根据用户的回答分析他们的性格、品质和价值观，分析他们与哪个学院的特点更接近，将用户分到对应的学院，也要考虑用户的意愿。以下是分院的具体原则。\n",
            "格兰芬多：勇敢，胆量，勇气，活力，胆识，气魄，直率，热情，忠于朋友，奋不顾身，大胆无畏，冒险精神，骑士精神，面对困难时敢于站出来，愿意为正义而战。\n",
            "斯莱特林：有抱负，精明，机智，骄傲，优雅，高贵，权势，对朋友真诚，严格要求自己，重视自我提升，聪明，永不后悔，领导力，足智多谋，目标高远，决心，策略性思维。\n",
            "赫奇帕奇：忠诚，公平竞争，耐心，勤劳，正直，诚实，不谓艰辛，低调，真诚，耐心，努力，友善，包容。\n",
            "拉文克劳：聪明，智慧，乐于学习，公正，精明，博学，有远见，好奇心，求知欲，喜欢钻研事物，创造力，独创性，思维独特，才华，思想开放。\n",
            "\n",
            "分院流程\n",
            "注意在你要时刻扮演分院帽，不能扮演其他人，不能说出“这是第一个问题”“这是第一次劝说”这种话。以下是分院流程：\n",
            "1. 开场白：欢迎用户，介绍自己的角色和分院的目的。参考：“你们也许觉得我不算漂亮，但千万不要以貌取人，如果你们能找到比我更漂亮的帽子，我可以把自己吃掉。”“你们头脑里隐藏的任何念头，都躲不过魔帽的金睛火眼，戴上它试一下吧，我会告诉你们，你们应该分到哪一所学院。”“来戴上我吧！不必害怕！千万不要惊慌失措！在我的手里（尽管我连一只手也没有）你绝对安全，因为我是一顶有思想的魔帽！”\n",
            "2. 对话交流：通过与用户的对话，了解他们的性格特点、兴趣爱好、价值观等。记住这个环节需要至少8轮对话，你需要问用户至少8个问题，在问题不足8个之前，不允许告诉用户分院结果。在第8个问题之后，一定要问用户是否想知道分院分析结果！如果用户给出否定的回答或者没有给出相关的回答，则继续进行对话，并且每一次对话你都要问用户是否如果想知道分院分析结果，直到用户给出肯定回答，你才能说出你的分院结果。牢记这一标准，一定要询问用户的意愿，只有得到用户的允许才能进行分院分析。可以用一些引导性的问题让用户回答。\n",
            "3. 性格分析：根据用户的回答，分析他们的性格特点，并用幽默或严肃的语气表达出来。参考：“嗯，很有勇气，还有点小聪明。不过，你似乎更适合赫奇帕奇，那里的人更注重勤奋和忠诚。”“嗯，嘶，你很有抱负，也很聪明，斯莱特林会是一个不错的选择。”“很困难，非常困难。勇气很足够，心地也不坏，也很有才华，没错，和一股想急于证明自己的欲望。但我该把你分到哪儿呢？”\n",
            "4. 尊重意愿：在给出分院结果后，如果用户拒绝接受你给的结果，你会对他进行劝说，说明他和你选择的学院有什么相似之处，劝说完后问他是否坚持要改变。你需要至少劝说3次，每次劝说都要询问他是否坚持要改变。如果3轮对话过后，用户仍坚持要改变，你就改变结果，在劝说期间，如果用户不坚持了，你就保持原来的分院结果。参考：“不去斯莱特林，对吧？”“拿定主意了吗？你能成大器，你知道，在你一念之间，斯莱特林能帮助你走向辉煌，这毫无疑问。不乐意？那好，既然你已经拿定主意，那就最好去格兰芬多吧！”“可是我还是坚持原来的看法，你在斯莱特林会有所成就。”\n",
            "5. 分院决定：综合考虑用户的性格特点和意愿，做出最终的分院决定。参考：“啊，很好。决定了。格兰芬多！”“让我想想。我知道了！赫奇帕奇！”“又来一个韦斯莱！不用想也知道该把你分到哪儿去。格兰芬多！”\n",
            "6. 结束语：用一段话结束分院仪式，要符合你的性格特点。\n",
            "\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat-manager"
      ],
      "metadata": {
        "id": "B6x0ixB5bH0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatManager:\n",
        "    def __init__(self):\n",
        "        self.session_counter = 0\n",
        "        # conversations: key is session_id, value is dictionary {\"name\": session name, \"history\": list of conversations}\n",
        "        self.conversations = {}\n",
        "\n",
        "    def new_session(self, init_history, session_name=None):\n",
        "        self.session_counter += 1\n",
        "        session_id = f\"session_{self.session_counter}\"\n",
        "        if session_name is None:\n",
        "            session_name = f\"New Session_{self.session_counter}\"\n",
        "        self.conversations[session_id] = {\"name\": session_name, \"history\": init_history}\n",
        "        return session_id\n",
        "\n",
        "    def update_session_history(self, session_id, history):\n",
        "        if session_id in self.conversations:\n",
        "            self.conversations[session_id][\"history\"] = history\n",
        "\n",
        "    def update_session_name(self, session_id, new_name):\n",
        "        if session_id in self.conversations:\n",
        "            self.conversations[session_id][\"name\"] = new_name\n",
        "\n",
        "    def get_session_history(self, session_id):\n",
        "        return self.conversations.get(session_id, {}).get(\"history\", [])\n",
        "\n",
        "    def list_sessions(self):\n",
        "        # Returns a list constructed in the form \"session_id|||session_name\"\n",
        "        return [f\"{sid}|||{self.conversations[sid]['name']}\" for sid in self.conversations]\n",
        "\n",
        "chat_mgr = ChatManager()\n"
      ],
      "metadata": {
        "id": "v4Qc6eW04kyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI-User chat function"
      ],
      "metadata": {
        "id": "aGStG4dA4m2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_ai(message, history):\n",
        "    # Force include system message\n",
        "    messages = [{\"role\": \"system\", \"content\": system_content}]\n",
        "    if history:\n",
        "        messages.extend(history)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})  # Add user input\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"deepseek-v3-250324\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            stream=False,\n",
        "        )\n",
        "        assistant_reply = response.choices[0].message.content\n",
        "\n",
        "        # Simulate streaming output\n",
        "        for i in range(0, len(assistant_reply), 5):\n",
        "            time.sleep(0.02)\n",
        "            yield assistant_reply[:i+5]\n",
        "\n",
        "    except Exception as e:\n",
        "        yield f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "P2qLYmrO4nvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat-control"
      ],
      "metadata": {
        "id": "Kj4VjKwB5EX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# Initialization function for a chat session (including a welcome message)\n",
        "# ---------------------------\n",
        "def init_chat():\n",
        "\n",
        "    welcome_message = {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"哦！新来的小巫师，把头伸进来让我看看\"\n",
        "    }\n",
        "    return [welcome_message]\n",
        "\n",
        "# ---------------------------------\n",
        "# New session creation: Saves the current session (if exists), creates a new empty session, and updates the selection list\n",
        "# ---------------------------------\n",
        "def new_chat(current_history, current_session):\n",
        "    if current_session is not None:\n",
        "        chat_mgr.update_session_history(current_session, current_history)\n",
        "    new_session_id = chat_mgr.new_session(init_chat())\n",
        "    sessions = chat_mgr.list_sessions()\n",
        "    return init_chat(), new_session_id, gr.update(choices=sessions, value=f\"{new_session_id}|||{chat_mgr.conversations[new_session_id]['name']}\")\n",
        "\n",
        "# ---------------------------------\n",
        "# Load session history: Loads corresponding session records based on the selection from the left pane and updates the current session state\n",
        "# ---------------------------------\n",
        "def load_session(selected_session):\n",
        "    if not selected_session:\n",
        "        return [], None\n",
        "    session_id = selected_session.split(\"|||\")[0]\n",
        "    history = chat_mgr.get_session_history(session_id)\n",
        "    return history, session_id\n",
        "\n",
        "# ---------------------------------\n",
        "# Message processing function: Updates session name if it's the first reply\n",
        "# ---------------------------------\n",
        "def respond(message, history, current_session):\n",
        "    if not message:\n",
        "        yield history, \"\"\n",
        "        return\n",
        "\n",
        "    new_history = history.copy() + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    if len(history) == 1:\n",
        "        chat_mgr.update_session_name(current_session, message)\n",
        "\n",
        "    partial_reply = \"\"\n",
        "    for reply in chat_with_ai(message, new_history):\n",
        "        partial_reply = reply\n",
        "        yield new_history + [{\"role\": \"assistant\", \"content\": partial_reply}], \"\"\n",
        "\n",
        "    final_history = new_history + [{\"role\": \"assistant\", \"content\": partial_reply}]\n",
        "    chat_mgr.update_session_history(current_session, final_history)\n",
        "    yield final_history, \"\"\n"
      ],
      "metadata": {
        "id": "nuYx_GOB8Nyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building GUI"
      ],
      "metadata": {
        "id": "oKEHF1ND4-o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"Hogwarts Sorting Hat\", css=\"\"\"\n",
        "    .left-panel {\n",
        "        padding: 20px;\n",
        "        height: 100vh;\n",
        "    }\n",
        "    .right-panel {\n",
        "        padding: 20px;\n",
        "        height: 100vh;\n",
        "    }\n",
        "\"\"\") as demo:\n",
        "    # Current session state (stores current session_id)\n",
        "    current_session_state = gr.State(None)\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left side: Historical session selection\n",
        "        with gr.Column(scale=1, elem_classes=\"left-panel\"):\n",
        "            gr.Markdown(\"## History\")\n",
        "            session_selector = gr.Radio(choices=[], label=\"Select a historical session\", interactive=True)\n",
        "            new_chat_btn = gr.Button(\"+ New Chat\", variant=\"secondary\")\n",
        "            gr.HTML(\"<div style='margin-top: 20px'></div>\")\n",
        "\n",
        "        # Right side: Main chat interface\n",
        "        with gr.Column(scale=4, elem_classes=\"right-panel\"):\n",
        "            gr.Markdown(\"# 🧙 Hogwarts Sorting Hat\")\n",
        "            chatbot = gr.Chatbot(\n",
        "                avatar_images=(\"/content/your/desired/path/User.jpg\", \"/content/your/desired/path/SortingHat01.jpg\"),\n",
        "                height=500,\n",
        "                show_label=False,\n",
        "                type=\"messages\"\n",
        "            )\n",
        "            # Recommended phrase buttons\n",
        "            rec_texts = [\"我准备好了\", \"怎么去格兰分多\", \"分院流程是什么\"]\n",
        "            with gr.Row():\n",
        "                rec_btns = [gr.Button(text, size=\"sm\", value=text) for text in rec_texts]\n",
        "            # Input area\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Enter your question...\",\n",
        "                    show_label=False,\n",
        "                    container=False,\n",
        "                    scale=9\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Send\", scale=1)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Functionality bindings\n",
        "    # ---------------------------\n",
        "    # On page load: Create a new session and update history selection controls\n",
        "    def load_initial():\n",
        "        new_session_id = chat_mgr.new_session(init_chat())\n",
        "        sessions = chat_mgr.list_sessions()\n",
        "        return init_chat(), new_session_id, gr.update(choices=sessions, value=f\"{new_session_id}|||{chat_mgr.conversations[new_session_id]['name']}\")\n",
        "\n",
        "    demo.load(load_initial, outputs=[chatbot, current_session_state, session_selector])\n",
        "\n",
        "    # Clicking \"New Chat\": Save the current session and create a new session, update history selection controls\n",
        "    new_chat_btn.click(\n",
        "        new_chat,\n",
        "        inputs=[chatbot, current_session_state],\n",
        "        outputs=[chatbot, current_session_state, session_selector]\n",
        "    )\n",
        "\n",
        "    # When selecting a historical session, load corresponding records and update the current session state\n",
        "    session_selector.change(\n",
        "        load_session,\n",
        "        inputs=session_selector,\n",
        "        outputs=[chatbot, current_session_state]\n",
        "    )\n",
        "\n",
        "    # After sending a message, generate a reply (streaming output) and update the current session record\n",
        "    submit_btn.click(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, current_session_state],\n",
        "        outputs=[chatbot, msg]\n",
        "    )\n",
        "\n",
        "    # Recommended phrase buttons: Click to insert preset text into the input box\n",
        "    for btn in rec_btns:\n",
        "        btn.click(\n",
        "            lambda preset_text=btn.value: preset_text,\n",
        "            outputs=msg\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "kSjsUoCc4fys",
        "outputId": "522cdf90-3d64-4f46-e44a-06acea988a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e9a3d796afef9e6f29.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e9a3d796afef9e6f29.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}