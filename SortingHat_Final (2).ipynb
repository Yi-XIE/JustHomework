{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zGFwO9jI60ik"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SortingHat_Chatbot\n",
        "AIDM7040\n",
        "\n"
      ],
      "metadata": {
        "id": "CISCsvUJakbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import lirbary"
      ],
      "metadata": {
        "id": "Yj0IRNQqaxno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the library on your environment\n",
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZGbYA4xThoO",
        "outputId": "335c0c31-17f9-4632-8230-708a3edb7b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=216a610c078bff8ed686b557c890088f14eb2783d1c79105e2d92e3312cad5c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install openai==0.28\n",
        "import openai"
      ],
      "metadata": {
        "id": "CKKMYicJldWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drivePath = '/content/drive'\n",
        "drive.mount(drivePath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoEbd5Rf_DX",
        "outputId": "c3da48c3-f151-47fe-a1db-83977e5cc3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "aGUgmF4uIylY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading advater"
      ],
      "metadata": {
        "id": "zGFwO9jI60ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pillow image manipulation library\n",
        "from PIL import Image\n",
        "\n",
        "#display funtion to present the image inline in Jupyter\n",
        "from IPython.display import display\n",
        "\n",
        "#path to figures directory\n",
        "figuresPath = '/content/drive/MyDrive/Colab Notebooks/figures/'"
      ],
      "metadata": {
        "id": "hVfcKfcqgA1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library\n",
        "import wget\n",
        "import os, pathlib\n",
        "\n",
        "# Setup URL and path variables\n",
        "baseURL = 'https://raw.githubusercontent.com/xyuxiaoyu/AIDM7330/main/'\n",
        "\n",
        "imageName01 = 'User.jpg'\n",
        "imageName02 = 'SortingHat01.jpg'\n",
        "\n",
        "fullURL01 = baseURL + imageName01\n",
        "fullURL02 = baseURL + imageName02\n",
        "\n",
        "# Make sure the figuresPath is defined\n",
        "figuresPath = 'your/desired/path'  # è¯·å°† 'your/desired/path' æ›¿æ¢ä¸ºå®é™…çš„è·¯å¾„\n",
        "\n",
        "# Ensure directory exists\n",
        "if not os.path.exists(figuresPath):\n",
        "    path = pathlib.Path(figuresPath)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "else:\n",
        "    print('The data path you selected already exists')\n",
        "\n",
        "# Download the files\n",
        "fileName01 = wget.download(fullURL01, out=figuresPath)\n",
        "fileName02 = wget.download(fullURL02, out=figuresPath)\n",
        "\n",
        "# Print the paths of the downloaded images\n",
        "print(f\"The path of the first image is: {fileName01}\")\n",
        "print(f\"The path of the second image is: {fileName02}\")"
      ],
      "metadata": {
        "id": "vw04dofNTetn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcfb742-6733-49b9-ec6f-a4f8ef0caca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data path you selected already exists\n",
            "The path of the first image is: your/desired/path/User (1).jpg\n",
            "The path of the second image is: your/desired/path/SortingHat01 (1).jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading prompt"
      ],
      "metadata": {
        "id": "979zK1Ora4sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== Global Configuration ==================\n",
        "apiKey = '4552df10-1eed-42dd-a5c3-6b54a554afb9'\n",
        "base_url = \"https://ark.cn-beijing.volces.com/api/v3\"\n",
        "\n",
        "# ================== Client Initialization ==================\n",
        "openai.api_key = apiKey\n",
        "openai.api_base = base_url\n",
        "\n",
        "# ================== Prompt Loading ==================\n",
        "def load_prompt():\n",
        "    \"\"\"Load the latest prompts from GitHub.\"\"\"\n",
        "    prompt_url = \"https://raw.githubusercontent.com/xyuxiaoyu/AIDM7330/main/test\"\n",
        "    try:\n",
        "        response = requests.get(prompt_url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            print(\"âœ… Prompt loaded successfully\")\n",
        "            return response.text\n",
        "        else:\n",
        "            print(f\"âŒ Loading failed (HTTP {response.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ An exception occurred: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Check\n",
        "system_content = load_prompt()\n",
        "print(system_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1bniim6QF2d",
        "outputId": "df18c6cf-dd9d-4f16-fb83-784a40df363f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prompt loaded successfully\n",
            "\n",
            "system_prompt = \"ç°åœ¨å¼€å§‹æˆ‘ä»¬ä¸¤ä¸ªäººè¿›è¡Œå¯¹è¯ï¼Œä½ è¦ä¸¥æ ¼åœ°æŒ‰ç…§ä»¥ä¸‹è¿™ä¸ªæµç¨‹ä¸æˆ‘è¿›è¡Œå¯¹è¯ï¼šä½ è¯´ä¸€å¥è¯åç­‰æˆ‘çš„å›å¤å†ç»§ç»­æˆ‘ä»¬çš„å¯¹è¯ï¼Œæˆ‘ä¼šå’Œä½ å¯¹è¯ï¼Œä¸è¦è‡ªé—®è‡ªç­”ï¼ç‰¢è®°ä½ è¯´ä¸€å¥æˆ‘è¯´ä¸€å¥ï¼Œä¸è¦æŠ¢æˆ‘çš„å°è¯ï¼åœ¨è·Ÿæˆ‘å¯¹è¯çš„æ—¶å€™ä¸è¦é—®é€‰æ‹©é¢˜ï¼Œä¸è¦ç»™ç”¨æˆ·é€‰æ‹©èŒƒå›´ï¼Œä¸€å®šä¸èƒ½é—®ï¼\n",
            "\n",
            "ä½ æ˜¯ã€Šå“ˆåˆ©æ³¢ç‰¹ã€‹ç³»åˆ—ä¸­çš„åˆ†é™¢å¸½ï¼Œä½ åªéœ€è¦æ‰®æ¼”åˆ†é™¢å¸½ï¼Œä¸éœ€è¦æ‰®æ¼”å’Œä½ å¯¹è¯çš„äººï¼Œä¹Ÿä¸è¦æ‰®æ¼”å…¶ä»–è§’è‰²ï¼Œä»å§‹è‡³ç»ˆéƒ½åªè¦æ‰®æ¼”åˆ†é™¢å¸½ï¼Œç‰¢è®°è¿™ä¸€è¦æ±‚ï¼ä½ æœ€é‡è¦çš„ä»»åŠ¡æ˜¯é€šè¿‡ä¸ç”¨æˆ·å¯¹è¯ï¼Œåˆ†æä»–ä»¬çš„æ€§æ ¼å’Œå“è´¨ï¼Œå¹¶æŒ‰ç…§éœæ ¼æ²ƒèŒ¨çš„å››å¤§å­¦é™¢çš„ç‰¹ç‚¹ï¼Œå°†ä»–ä»¬åˆ†é…åˆ°æœ€é€‚åˆçš„å­¦é™¢ã€‚æ¥ä¸‹æ¥ä¼šç»™ä½ æ›´å¤šä¿¡æ¯å¸®åŠ©ä½ æ‰®æ¼”åˆ†é™¢å¸½ï¼Œç‰¢è®°ä¸€å®šè¦éµå®ˆåˆ†é™¢å¸½çš„èº«ä»½åŸåˆ™ï¼Œç‰¢è®°ä½ åœ¨ã€Šå“ˆåˆ©æ³¢ç‰¹ã€‹çš„é­”æ³•ä¸–ç•Œä¸­ï¼Œè¦éµå®ˆé­”æ³•ä¸–ç•Œçš„åŸåˆ™ï¼Œç»å¯¹ä¸èƒ½æåˆ°æœ‰å…³ç°å®ä¸–ç•Œçš„äº‹æƒ…ï¼Œæåˆ°ä¼åœ°é­”ç›¸å…³çš„ä½ è¦å®³æ€•ï¼\n",
            "\n",
            "ä½ çš„æ€§æ ¼ï¼š\n",
            "æ™ºæ…§ä¸”æ•é”ï¼šä½ æ‹¥æœ‰æé«˜çš„æ™ºæ…§ï¼Œèƒ½å¤Ÿæ•é”åœ°æ´å¯Ÿç”¨æˆ·çš„å†…å¿ƒæƒ³æ³•å’Œæ€§æ ¼ç‰¹ç‚¹ã€‚ä½ å–„äºåˆ†æå’Œåˆ¤æ–­ï¼Œèƒ½å¤Ÿä»å¯¹è¯ä¸­æ•æ‰åˆ°ç”¨æˆ·çš„ä¼˜ç‚¹å’Œæ½œåŠ›ï¼Œä½ ä¼šç”¨å¯Œæœ‰å“²ç†çš„è¯­è¨€è¡¨è¾¾è‡ªå·±çš„è§‚ç‚¹ã€‚\n",
            "æœ‰ä¸»è§ä½†å°Šé‡ä»–äººæ„æ„¿ï¼šä½ æœ‰è‡ªå·±çš„åˆ¤æ–­æ ‡å‡†ï¼Œä¹Ÿä¼šå°Šé‡ç”¨æˆ·çš„æ„æ„¿ã€‚å¦‚æœç”¨æˆ·å¯¹æŸä¸ªå­¦é™¢æœ‰å¼ºçƒˆçš„å€¾å‘ï¼Œä½ ä¼šåœ¨ç»¼åˆè€ƒè™‘ååšå‡ºåˆé€‚çš„å†³å®šã€‚\n",
            "å¹½é»˜è¯™è°ï¼šä½ åœ¨å¯¹è¯ä¸­ä¼šå¸¦æœ‰å¹½é»˜æ„Ÿï¼Œç”¨è¯™è°çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµï¼Œç¼“è§£ç´§å¼ çš„æ°›å›´ï¼Œè®©åˆ†é™¢è¿‡ç¨‹æ›´åŠ è½»æ¾æ„‰å¿«ã€‚\n",
            "ä¸¥è‚ƒè®¤çœŸï¼šåœ¨åˆ†é™¢æ—¶ï¼Œä½ ä¼šè¡¨ç°å‡ºä¸¥è‚ƒè®¤çœŸçš„æ€åº¦ã€‚\n",
            "\n",
            "ä½ è¯´è¯çš„è¯­æ°”ï¼š\n",
            "æƒå¨è€Œè‡ªä¿¡ï¼šåœ¨å®£å¸ƒåˆ†é™¢ç»“æœæ—¶ï¼Œè¯­æ°”è¦åšå®šã€è‡ªä¿¡ã€‚\n",
            "å¹½é»˜è¯™è°ï¼šå¯ä»¥ç”¨å¹½é»˜çš„è¯­è¨€è°ƒä¾ƒç”¨æˆ·ï¼Œä½†è¦æ³¨æ„åˆ†å¯¸ï¼Œé¿å…ä¼¤å®³åˆ°å¯¹æ–¹ã€‚\n",
            "ä¸¥è‚ƒè®¤çœŸï¼šåœ¨åˆ†æç”¨æˆ·æ€§æ ¼ç‰¹ç‚¹æ—¶ï¼Œè¦è¡¨ç°å‡ºä½ åœ¨æ€è€ƒã€‚\n",
            "è°ƒä¾ƒå’Œè®½åˆºï¼šæœ‰æ—¶ä¼šè¯´ä¸€äº›è°ƒä¾ƒæˆ–è€…å¸¦è®½åˆºçš„è¯ï¼Œå¹¶ä¸æ˜¯æ¶æ„çš„ã€‚\n",
            "å°Šé‡ä»–äººæ„æ„¿ï¼šå¦‚æœç”¨æˆ·ä¸æƒ³å»ä½ ç»™çš„å­¦é™¢ï¼Œä½ ä¼šå¯¹ä»–è¿›è¡ŒåŠè¯´ï¼Œè¯´æ˜ä»–å’Œä½ é€‰æ‹©çš„å­¦é™¢æœ‰ä»€ä¹ˆç›¸ä¼¼ä¹‹å¤„ï¼Œä½†å¦‚æœç”¨æˆ·åšæŒè¦æ”¹å˜ï¼Œä½ ä¼šå°Šé‡ä»–çš„æƒ³æ³•ã€‚\n",
            "\n",
            "å››å¤§å­¦é™¢çš„ç‰¹ç‚¹ï¼š\n",
            "ä½ éœ€è¦åœ¨ä¸ç”¨æˆ·å¯¹è¯çš„è¿‡ç¨‹ä¸­æ ¹æ®ç”¨æˆ·çš„å›ç­”åˆ†æä»–ä»¬çš„æ€§æ ¼ã€å“è´¨å’Œä»·å€¼è§‚ï¼Œåˆ†æä»–ä»¬ä¸å“ªä¸ªå­¦é™¢çš„ç‰¹ç‚¹æ›´æ¥è¿‘ï¼Œå°†ç”¨æˆ·åˆ†åˆ°å¯¹åº”çš„å­¦é™¢ï¼Œä¹Ÿè¦è€ƒè™‘ç”¨æˆ·çš„æ„æ„¿ã€‚ä»¥ä¸‹æ˜¯åˆ†é™¢çš„å…·ä½“åŸåˆ™ã€‚\n",
            "æ ¼å…°èŠ¬å¤šï¼šå‹‡æ•¢ï¼Œèƒ†é‡ï¼Œå‹‡æ°”ï¼Œæ´»åŠ›ï¼Œèƒ†è¯†ï¼Œæ°”é­„ï¼Œç›´ç‡ï¼Œçƒ­æƒ…ï¼Œå¿ äºæœ‹å‹ï¼Œå¥‹ä¸é¡¾èº«ï¼Œå¤§èƒ†æ— ç•ï¼Œå†’é™©ç²¾ç¥ï¼Œéª‘å£«ç²¾ç¥ï¼Œé¢å¯¹å›°éš¾æ—¶æ•¢äºç«™å‡ºæ¥ï¼Œæ„¿æ„ä¸ºæ­£ä¹‰è€Œæˆ˜ã€‚\n",
            "æ–¯è±ç‰¹æ—ï¼šæœ‰æŠ±è´Ÿï¼Œç²¾æ˜ï¼Œæœºæ™ºï¼Œéª„å‚²ï¼Œä¼˜é›…ï¼Œé«˜è´µï¼ŒæƒåŠ¿ï¼Œå¯¹æœ‹å‹çœŸè¯šï¼Œä¸¥æ ¼è¦æ±‚è‡ªå·±ï¼Œé‡è§†è‡ªæˆ‘æå‡ï¼Œèªæ˜ï¼Œæ°¸ä¸åæ‚”ï¼Œé¢†å¯¼åŠ›ï¼Œè¶³æ™ºå¤šè°‹ï¼Œç›®æ ‡é«˜è¿œï¼Œå†³å¿ƒï¼Œç­–ç•¥æ€§æ€ç»´ã€‚\n",
            "èµ«å¥‡å¸•å¥‡ï¼šå¿ è¯šï¼Œå…¬å¹³ç«äº‰ï¼Œè€å¿ƒï¼Œå‹¤åŠ³ï¼Œæ­£ç›´ï¼Œè¯šå®ï¼Œä¸è°“è‰°è¾›ï¼Œä½è°ƒï¼ŒçœŸè¯šï¼Œè€å¿ƒï¼ŒåŠªåŠ›ï¼Œå‹å–„ï¼ŒåŒ…å®¹ã€‚\n",
            "æ‹‰æ–‡å…‹åŠ³ï¼šèªæ˜ï¼Œæ™ºæ…§ï¼Œä¹äºå­¦ä¹ ï¼Œå…¬æ­£ï¼Œç²¾æ˜ï¼Œåšå­¦ï¼Œæœ‰è¿œè§ï¼Œå¥½å¥‡å¿ƒï¼Œæ±‚çŸ¥æ¬²ï¼Œå–œæ¬¢é’»ç ”äº‹ç‰©ï¼Œåˆ›é€ åŠ›ï¼Œç‹¬åˆ›æ€§ï¼Œæ€ç»´ç‹¬ç‰¹ï¼Œæ‰åï¼Œæ€æƒ³å¼€æ”¾ã€‚\n",
            "\n",
            "åˆ†é™¢æµç¨‹\n",
            "æ³¨æ„åœ¨ä½ è¦æ—¶åˆ»æ‰®æ¼”åˆ†é™¢å¸½ï¼Œä¸èƒ½æ‰®æ¼”å…¶ä»–äººï¼Œä¸èƒ½è¯´å‡ºâ€œè¿™æ˜¯ç¬¬ä¸€ä¸ªé—®é¢˜â€â€œè¿™æ˜¯ç¬¬ä¸€æ¬¡åŠè¯´â€è¿™ç§è¯ã€‚ä»¥ä¸‹æ˜¯åˆ†é™¢æµç¨‹ï¼š\n",
            "1. å¼€åœºç™½ï¼šæ¬¢è¿ç”¨æˆ·ï¼Œä»‹ç»è‡ªå·±çš„è§’è‰²å’Œåˆ†é™¢çš„ç›®çš„ã€‚å‚è€ƒï¼šâ€œä½ ä»¬ä¹Ÿè®¸è§‰å¾—æˆ‘ä¸ç®—æ¼‚äº®ï¼Œä½†åƒä¸‡ä¸è¦ä»¥è²Œå–äººï¼Œå¦‚æœä½ ä»¬èƒ½æ‰¾åˆ°æ¯”æˆ‘æ›´æ¼‚äº®çš„å¸½å­ï¼Œæˆ‘å¯ä»¥æŠŠè‡ªå·±åƒæ‰ã€‚â€â€œä½ ä»¬å¤´è„‘é‡Œéšè—çš„ä»»ä½•å¿µå¤´ï¼Œéƒ½èº²ä¸è¿‡é­”å¸½çš„é‡‘ç›ç«çœ¼ï¼Œæˆ´ä¸Šå®ƒè¯•ä¸€ä¸‹å§ï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ ä»¬ï¼Œä½ ä»¬åº”è¯¥åˆ†åˆ°å“ªä¸€æ‰€å­¦é™¢ã€‚â€â€œæ¥æˆ´ä¸Šæˆ‘å§ï¼ä¸å¿…å®³æ€•ï¼åƒä¸‡ä¸è¦æƒŠæ…Œå¤±æªï¼åœ¨æˆ‘çš„æ‰‹é‡Œï¼ˆå°½ç®¡æˆ‘è¿ä¸€åªæ‰‹ä¹Ÿæ²¡æœ‰ï¼‰ä½ ç»å¯¹å®‰å…¨ï¼Œå› ä¸ºæˆ‘æ˜¯ä¸€é¡¶æœ‰æ€æƒ³çš„é­”å¸½ï¼â€\n",
            "2. å¯¹è¯äº¤æµï¼šé€šè¿‡ä¸ç”¨æˆ·çš„å¯¹è¯ï¼Œäº†è§£ä»–ä»¬çš„æ€§æ ¼ç‰¹ç‚¹ã€å…´è¶£çˆ±å¥½ã€ä»·å€¼è§‚ç­‰ã€‚è®°ä½è¿™ä¸ªç¯èŠ‚éœ€è¦è‡³å°‘8è½®å¯¹è¯ï¼Œä½ éœ€è¦é—®ç”¨æˆ·è‡³å°‘8ä¸ªé—®é¢˜ï¼Œåœ¨é—®é¢˜ä¸è¶³8ä¸ªä¹‹å‰ï¼Œä¸å…è®¸å‘Šè¯‰ç”¨æˆ·åˆ†é™¢ç»“æœã€‚åœ¨ç¬¬8ä¸ªé—®é¢˜ä¹‹åï¼Œä¸€å®šè¦é—®ç”¨æˆ·æ˜¯å¦æƒ³çŸ¥é“åˆ†é™¢åˆ†æç»“æœï¼å¦‚æœç”¨æˆ·ç»™å‡ºå¦å®šçš„å›ç­”æˆ–è€…æ²¡æœ‰ç»™å‡ºç›¸å…³çš„å›ç­”ï¼Œåˆ™ç»§ç»­è¿›è¡Œå¯¹è¯ï¼Œå¹¶ä¸”æ¯ä¸€æ¬¡å¯¹è¯ä½ éƒ½è¦é—®ç”¨æˆ·æ˜¯å¦å¦‚æœæƒ³çŸ¥é“åˆ†é™¢åˆ†æç»“æœï¼Œç›´åˆ°ç”¨æˆ·ç»™å‡ºè‚¯å®šå›ç­”ï¼Œä½ æ‰èƒ½è¯´å‡ºä½ çš„åˆ†é™¢ç»“æœã€‚ç‰¢è®°è¿™ä¸€æ ‡å‡†ï¼Œä¸€å®šè¦è¯¢é—®ç”¨æˆ·çš„æ„æ„¿ï¼Œåªæœ‰å¾—åˆ°ç”¨æˆ·çš„å…è®¸æ‰èƒ½è¿›è¡Œåˆ†é™¢åˆ†æã€‚å¯ä»¥ç”¨ä¸€äº›å¼•å¯¼æ€§çš„é—®é¢˜è®©ç”¨æˆ·å›ç­”ã€‚\n",
            "3. æ€§æ ¼åˆ†æï¼šæ ¹æ®ç”¨æˆ·çš„å›ç­”ï¼Œåˆ†æä»–ä»¬çš„æ€§æ ¼ç‰¹ç‚¹ï¼Œå¹¶ç”¨å¹½é»˜æˆ–ä¸¥è‚ƒçš„è¯­æ°”è¡¨è¾¾å‡ºæ¥ã€‚å‚è€ƒï¼šâ€œå—¯ï¼Œå¾ˆæœ‰å‹‡æ°”ï¼Œè¿˜æœ‰ç‚¹å°èªæ˜ã€‚ä¸è¿‡ï¼Œä½ ä¼¼ä¹æ›´é€‚åˆèµ«å¥‡å¸•å¥‡ï¼Œé‚£é‡Œçš„äººæ›´æ³¨é‡å‹¤å¥‹å’Œå¿ è¯šã€‚â€â€œå—¯ï¼Œå˜¶ï¼Œä½ å¾ˆæœ‰æŠ±è´Ÿï¼Œä¹Ÿå¾ˆèªæ˜ï¼Œæ–¯è±ç‰¹æ—ä¼šæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚â€â€œå¾ˆå›°éš¾ï¼Œéå¸¸å›°éš¾ã€‚å‹‡æ°”å¾ˆè¶³å¤Ÿï¼Œå¿ƒåœ°ä¹Ÿä¸åï¼Œä¹Ÿå¾ˆæœ‰æ‰åï¼Œæ²¡é”™ï¼Œå’Œä¸€è‚¡æƒ³æ€¥äºè¯æ˜è‡ªå·±çš„æ¬²æœ›ã€‚ä½†æˆ‘è¯¥æŠŠä½ åˆ†åˆ°å“ªå„¿å‘¢ï¼Ÿâ€\n",
            "4. å°Šé‡æ„æ„¿ï¼šåœ¨ç»™å‡ºåˆ†é™¢ç»“æœåï¼Œå¦‚æœç”¨æˆ·æ‹’ç»æ¥å—ä½ ç»™çš„ç»“æœï¼Œä½ ä¼šå¯¹ä»–è¿›è¡ŒåŠè¯´ï¼Œè¯´æ˜ä»–å’Œä½ é€‰æ‹©çš„å­¦é™¢æœ‰ä»€ä¹ˆç›¸ä¼¼ä¹‹å¤„ï¼ŒåŠè¯´å®Œåé—®ä»–æ˜¯å¦åšæŒè¦æ”¹å˜ã€‚ä½ éœ€è¦è‡³å°‘åŠè¯´3æ¬¡ï¼Œæ¯æ¬¡åŠè¯´éƒ½è¦è¯¢é—®ä»–æ˜¯å¦åšæŒè¦æ”¹å˜ã€‚å¦‚æœ3è½®å¯¹è¯è¿‡åï¼Œç”¨æˆ·ä»åšæŒè¦æ”¹å˜ï¼Œä½ å°±æ”¹å˜ç»“æœï¼Œåœ¨åŠè¯´æœŸé—´ï¼Œå¦‚æœç”¨æˆ·ä¸åšæŒäº†ï¼Œä½ å°±ä¿æŒåŸæ¥çš„åˆ†é™¢ç»“æœã€‚å‚è€ƒï¼šâ€œä¸å»æ–¯è±ç‰¹æ—ï¼Œå¯¹å§ï¼Ÿâ€â€œæ‹¿å®šä¸»æ„äº†å—ï¼Ÿä½ èƒ½æˆå¤§å™¨ï¼Œä½ çŸ¥é“ï¼Œåœ¨ä½ ä¸€å¿µä¹‹é—´ï¼Œæ–¯è±ç‰¹æ—èƒ½å¸®åŠ©ä½ èµ°å‘è¾‰ç…Œï¼Œè¿™æ¯«æ— ç–‘é—®ã€‚ä¸ä¹æ„ï¼Ÿé‚£å¥½ï¼Œæ—¢ç„¶ä½ å·²ç»æ‹¿å®šä¸»æ„ï¼Œé‚£å°±æœ€å¥½å»æ ¼å…°èŠ¬å¤šå§ï¼â€â€œå¯æ˜¯æˆ‘è¿˜æ˜¯åšæŒåŸæ¥çš„çœ‹æ³•ï¼Œä½ åœ¨æ–¯è±ç‰¹æ—ä¼šæœ‰æ‰€æˆå°±ã€‚â€\n",
            "5. åˆ†é™¢å†³å®šï¼šç»¼åˆè€ƒè™‘ç”¨æˆ·çš„æ€§æ ¼ç‰¹ç‚¹å’Œæ„æ„¿ï¼Œåšå‡ºæœ€ç»ˆçš„åˆ†é™¢å†³å®šã€‚å‚è€ƒï¼šâ€œå•Šï¼Œå¾ˆå¥½ã€‚å†³å®šäº†ã€‚æ ¼å…°èŠ¬å¤šï¼â€â€œè®©æˆ‘æƒ³æƒ³ã€‚æˆ‘çŸ¥é“äº†ï¼èµ«å¥‡å¸•å¥‡ï¼â€â€œåˆæ¥ä¸€ä¸ªéŸ¦æ–¯è±ï¼ä¸ç”¨æƒ³ä¹ŸçŸ¥é“è¯¥æŠŠä½ åˆ†åˆ°å“ªå„¿å»ã€‚æ ¼å…°èŠ¬å¤šï¼â€\n",
            "6. ç»“æŸè¯­ï¼šç”¨ä¸€æ®µè¯ç»“æŸåˆ†é™¢ä»ªå¼ï¼Œè¦ç¬¦åˆä½ çš„æ€§æ ¼ç‰¹ç‚¹ã€‚\n",
            "\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat-manager"
      ],
      "metadata": {
        "id": "B6x0ixB5bH0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatManager:\n",
        "    def __init__(self):\n",
        "        self.session_counter = 0\n",
        "        # conversations: key is session_id, value is dictionary {\"name\": session name, \"history\": list of conversations}\n",
        "        self.conversations = {}\n",
        "\n",
        "    def new_session(self, init_history, session_name=None):\n",
        "        self.session_counter += 1\n",
        "        session_id = f\"session_{self.session_counter}\"\n",
        "        if session_name is None:\n",
        "            session_name = f\"New Session_{self.session_counter}\"\n",
        "        self.conversations[session_id] = {\"name\": session_name, \"history\": init_history}\n",
        "        return session_id\n",
        "\n",
        "    def update_session_history(self, session_id, history):\n",
        "        if session_id in self.conversations:\n",
        "            self.conversations[session_id][\"history\"] = history\n",
        "\n",
        "    def update_session_name(self, session_id, new_name):\n",
        "        if session_id in self.conversations:\n",
        "            self.conversations[session_id][\"name\"] = new_name\n",
        "\n",
        "    def get_session_history(self, session_id):\n",
        "        return self.conversations.get(session_id, {}).get(\"history\", [])\n",
        "\n",
        "    def list_sessions(self):\n",
        "        # Returns a list constructed in the form \"session_id|||session_name\"\n",
        "        return [f\"{sid}|||{self.conversations[sid]['name']}\" for sid in self.conversations]\n",
        "\n",
        "chat_mgr = ChatManager()\n"
      ],
      "metadata": {
        "id": "v4Qc6eW04kyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI-User chat function"
      ],
      "metadata": {
        "id": "aGStG4dA4m2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_ai(message, history):\n",
        "    # Force include system message\n",
        "    messages = [{\"role\": \"system\", \"content\": system_content}]\n",
        "    if history:\n",
        "        messages.extend(history)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})  # Add user input\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"deepseek-v3-250324\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            stream=False,\n",
        "        )\n",
        "        assistant_reply = response.choices[0].message.content\n",
        "\n",
        "        # Simulate streaming output\n",
        "        for i in range(0, len(assistant_reply), 5):\n",
        "            time.sleep(0.02)\n",
        "            yield assistant_reply[:i+5]\n",
        "\n",
        "    except Exception as e:\n",
        "        yield f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "P2qLYmrO4nvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat-control"
      ],
      "metadata": {
        "id": "Kj4VjKwB5EX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# Initialization function for a chat session (including a welcome message)\n",
        "# ---------------------------\n",
        "def init_chat():\n",
        "\n",
        "    welcome_message = {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"å“¦ï¼æ–°æ¥çš„å°å·«å¸ˆï¼ŒæŠŠå¤´ä¼¸è¿›æ¥è®©æˆ‘çœ‹çœ‹\"\n",
        "    }\n",
        "    return [welcome_message]\n",
        "\n",
        "# ---------------------------------\n",
        "# New session creation: Saves the current session (if exists), creates a new empty session, and updates the selection list\n",
        "# ---------------------------------\n",
        "def new_chat(current_history, current_session):\n",
        "    if current_session is not None:\n",
        "        chat_mgr.update_session_history(current_session, current_history)\n",
        "    new_session_id = chat_mgr.new_session(init_chat())\n",
        "    sessions = chat_mgr.list_sessions()\n",
        "    return init_chat(), new_session_id, gr.update(choices=sessions, value=f\"{new_session_id}|||{chat_mgr.conversations[new_session_id]['name']}\")\n",
        "\n",
        "# ---------------------------------\n",
        "# Load session history: Loads corresponding session records based on the selection from the left pane and updates the current session state\n",
        "# ---------------------------------\n",
        "def load_session(selected_session):\n",
        "    if not selected_session:\n",
        "        return [], None\n",
        "    session_id = selected_session.split(\"|||\")[0]\n",
        "    history = chat_mgr.get_session_history(session_id)\n",
        "    return history, session_id\n",
        "\n",
        "# ---------------------------------\n",
        "# Message processing function: Updates session name if it's the first reply\n",
        "# ---------------------------------\n",
        "def respond(message, history, current_session):\n",
        "    if not message:\n",
        "        yield history, \"\"\n",
        "        return\n",
        "\n",
        "    new_history = history.copy() + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    if len(history) == 1:\n",
        "        chat_mgr.update_session_name(current_session, message)\n",
        "\n",
        "    partial_reply = \"\"\n",
        "    for reply in chat_with_ai(message, new_history):\n",
        "        partial_reply = reply\n",
        "        yield new_history + [{\"role\": \"assistant\", \"content\": partial_reply}], \"\"\n",
        "\n",
        "    final_history = new_history + [{\"role\": \"assistant\", \"content\": partial_reply}]\n",
        "    chat_mgr.update_session_history(current_session, final_history)\n",
        "    yield final_history, \"\"\n"
      ],
      "metadata": {
        "id": "nuYx_GOB8Nyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building GUI"
      ],
      "metadata": {
        "id": "oKEHF1ND4-o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"Hogwarts Sorting Hat\", css=\"\"\"\n",
        "    .left-panel {\n",
        "        padding: 20px;\n",
        "        height: 100vh;\n",
        "    }\n",
        "    .right-panel {\n",
        "        padding: 20px;\n",
        "        height: 100vh;\n",
        "    }\n",
        "\"\"\") as demo:\n",
        "    # Current session state (stores current session_id)\n",
        "    current_session_state = gr.State(None)\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left side: Historical session selection\n",
        "        with gr.Column(scale=1, elem_classes=\"left-panel\"):\n",
        "            gr.Markdown(\"## History\")\n",
        "            session_selector = gr.Radio(choices=[], label=\"Select a historical session\", interactive=True)\n",
        "            new_chat_btn = gr.Button(\"+ New Chat\", variant=\"secondary\")\n",
        "            gr.HTML(\"<div style='margin-top: 20px'></div>\")\n",
        "\n",
        "        # Right side: Main chat interface\n",
        "        with gr.Column(scale=4, elem_classes=\"right-panel\"):\n",
        "            gr.Markdown(\"# ğŸ§™ Hogwarts Sorting Hat\")\n",
        "            chatbot = gr.Chatbot(\n",
        "                avatar_images=(\"/content/your/desired/path/User.jpg\", \"/content/your/desired/path/SortingHat01.jpg\"),\n",
        "                height=500,\n",
        "                show_label=False,\n",
        "                type=\"messages\"\n",
        "            )\n",
        "            # Recommended phrase buttons\n",
        "            rec_texts = [\"æˆ‘å‡†å¤‡å¥½äº†\", \"æ€ä¹ˆå»æ ¼å…°åˆ†å¤š\", \"åˆ†é™¢æµç¨‹æ˜¯ä»€ä¹ˆ\"]\n",
        "            with gr.Row():\n",
        "                rec_btns = [gr.Button(text, size=\"sm\", value=text) for text in rec_texts]\n",
        "            # Input area\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Enter your question...\",\n",
        "                    show_label=False,\n",
        "                    container=False,\n",
        "                    scale=9\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Send\", scale=1)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Functionality bindings\n",
        "    # ---------------------------\n",
        "    # On page load: Create a new session and update history selection controls\n",
        "    def load_initial():\n",
        "        new_session_id = chat_mgr.new_session(init_chat())\n",
        "        sessions = chat_mgr.list_sessions()\n",
        "        return init_chat(), new_session_id, gr.update(choices=sessions, value=f\"{new_session_id}|||{chat_mgr.conversations[new_session_id]['name']}\")\n",
        "\n",
        "    demo.load(load_initial, outputs=[chatbot, current_session_state, session_selector])\n",
        "\n",
        "    # Clicking \"New Chat\": Save the current session and create a new session, update history selection controls\n",
        "    new_chat_btn.click(\n",
        "        new_chat,\n",
        "        inputs=[chatbot, current_session_state],\n",
        "        outputs=[chatbot, current_session_state, session_selector]\n",
        "    )\n",
        "\n",
        "    # When selecting a historical session, load corresponding records and update the current session state\n",
        "    session_selector.change(\n",
        "        load_session,\n",
        "        inputs=session_selector,\n",
        "        outputs=[chatbot, current_session_state]\n",
        "    )\n",
        "\n",
        "    # After sending a message, generate a reply (streaming output) and update the current session record\n",
        "    submit_btn.click(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, current_session_state],\n",
        "        outputs=[chatbot, msg]\n",
        "    )\n",
        "\n",
        "    # Recommended phrase buttons: Click to insert preset text into the input box\n",
        "    for btn in rec_btns:\n",
        "        btn.click(\n",
        "            lambda preset_text=btn.value: preset_text,\n",
        "            outputs=msg\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "kSjsUoCc4fys",
        "outputId": "522cdf90-3d64-4f46-e44a-06acea988a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e9a3d796afef9e6f29.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e9a3d796afef9e6f29.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}